{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Machine Learning 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "There are innumerable machine learning models (and algorithms for fitting them to data) out there, and each one has something special about it that makes it suitable to a specific type of problem. To apply machine learning and get some initial results is fairly straight forward. Getting under the hood, however, requires a bit of work. This week we will look into how Decision Trees and PCA works. In the exercises today you will:\n",
    "\n",
    "* Implement a standard decision tree mechanism\n",
    "* Use PCA to visualize clusters in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Questions**](https://github.com/ulfaslak/computational_analysis_of_big_data_2018_fall/issues) **/** [**Feedback**](http://ulfaslak.com/vent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get started**: Load the data you used last week to classify hero/villainness. It should consist of two arrays, one of dimensions ($N_{characters}$, $N_{teams}$) which is your feature matrix that has the team alliances of each character as a row vector of ones and zeros, and another of dimensions ($N_{characters}$, ) which is your target array that gives whether a character is a hero (1) or a villain (0). You can either load the data or copy/paste the code that generates it.\n",
    "\n",
    "*Hint: If you had trouble with the data, use mine, called `affiliations.csv` in the `data` folder. You can load it as a `pandas.DataFrame`, with `pd.read_csv('data_team_alliances.csv', index_col=0)`. The rightmost column is the target array. Do not include this in PCA (think about why)!.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not exactly look right. Not sure what the problem could be, but I'm guessing you are not computing the average weighted entropy right.\n",
    "\n",
    "If you look in my slides from yesterday I give an example of how to compute the split entropy on page 18-23. The idea is that:\n",
    "\n",
    "The question you ask to your data (\"do you lay eggs\" or \"are you affiliated with the X-Men alliance?\") splits the data into to two subsets, one that answers yes to the question and one that answers no.\n",
    "In each of these subsets you can then compute the entropy of distribution of target values. In other words, if, say, in your first subset (the ones that answered \"yes\" and this were all affiliated with X-Men), there are 90% heroes, 3% villains and 7% ambiguous, the entropy of that distribution would be shannon_entropy([0.9, 0.03, 0.07]).\n",
    "You compute the target entropy of both your subsets.\n",
    "The weighted average entropy you can then compute by averaging the two numbers, with the twist that each term has to be weighted by how large the subset it estimates the entropy of is. Example: If the X-Men affiliated subset is 30 large and the non-X-Men subset is 1000, then the weighted average is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement the decision making algorithm of a decision tree classifier, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.1**: Read about [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory).\n",
    "1. What is it? How is it defined mathematically (write out the formula in LateX formatting)?\n",
    "2. Write a function that computes the Shannon-entropy of a probability vector. Compute the Shannon entropy of `p=[0.4, 0.6]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def shannon(p):\n",
    "    return -1.0*sum([x*np.log2(x) for x in p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.2**: Split your data into two subsets. One where characters are affiliated with X-men and one where they are not.\n",
    "1. What is the entropy of target labels in each subset?\n",
    "2. What is the weighted average entropy of the split?\n",
    "3. Write a function that computes the weighted average entropy of a split, given the data and team (name or id) on which to split the data.\n",
    "4. Plot the distribution of split entropy for all features. Comment on the result. My figure looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.2.2.4.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ml_data = pd.read_csv(\"affiliations.csv\", index_col=0)\n",
    "features = data.iloc[:,:-1]\n",
    "target = data.faction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def shannon(p):\n",
    "    return -1.0*sum([x*np.log2(x) for x in p])\n",
    "\n",
    "#solves for entropy of a split\n",
    "def compute_entropy(sdata):\n",
    "    size = 1.0*len(sdata)\n",
    "    count = Counter(sdata.faction)\n",
    "    dist = [1.0 * x/size for x in count.values()]\n",
    "    return size,shannon(dist)\n",
    "\n",
    "def compute_avg_ent_feature(pdata, feature):\n",
    "    \n",
    "    #split that contains this feature\n",
    "    side_1 = pdata[pdata[feature] == 1]\n",
    "    \n",
    "    #split that does not contain this feature\n",
    "    side_2 = pdata[pdata[feature] == 0]\n",
    "    \n",
    "    #compute the entropy of both brances and store their sizes\n",
    "    s1,ent_1 = compute_entropy(side_1)\n",
    "    s2,ent_2 = compute_entropy(side_2)\n",
    "    \n",
    "    #compute the entropy of the main and the size\n",
    "    p1,entropy_before = compute_entropy(pdata)\n",
    "    \n",
    "    #weight_1*entropy_1 + weight_2*entropy_2 \n",
    "    entropy_after = ((s1/p1)*ent_1 + (s2/p1)*ent_2)\n",
    "    \n",
    "    return entropy_after\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3600954091814654"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_ent_feature(ml_data,\"X-Men\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average of split entropy...[288 / 288] \r"
     ]
    }
   ],
   "source": [
    "#Plot the distribution of split entropy for all features. Comment on the result.\n",
    "import sys\n",
    "all_entropy = []\n",
    "progress = 0\n",
    "for progress,column in enumerate(data):\n",
    "    if column != 'faction':\n",
    "        all_entropy.append(compute_avg_ent_feature(data,column))\n",
    "        sys.stdout.write(\"Computing average of split entropy...[%d / %d] \\r\" % (progress+1,len(data.columns)-1))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"Distribution of split entropy for all features\")\n",
    "sns.kdeplot(all_entropy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    "### >**Ex. 5.1.3**: Print the maximum entropy path of a decision tree.\n",
    ">\n",
    ">1. Implement the following pseudocode and print the output:<br><br>\n",
    ">Step 1. Find `team` that gives lowest split entropy for `data`. Print `team`.<br>\n",
    ">Step 2. Split `data` on `team`, to produce `data0` and `data1`. Print the entropy of each, as well as their weighted avg. entropy.<br>\n",
    ">Step 3. Overwrite the `data` variable with either `data0` or `data1`, depending on which has the highest entropy.<br>\n",
    ">Step 4. Stop if there are less than 5 datapoints in `data`. Otherwise start over from 1.<br><br>\n",
    ">My output looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.2.3.1.png) for the first five splits.<br><br>\n",
    ">\n",
    ">2. Comment on decision path your code takes: How splits are there? Do you notice anything interesting about the final splits? Why do we choose to stop splitting before `data` get smaller than 5?\n",
    "\n",
    ">3. Train a `sklearn.tree.DecisionTreeClassifier` classifier on the dataset. Initiate the classifier with `criterion='entropy'`. What are the most important features of this classifier? How does this line up with the order of the order of splits you just printed (a comment is fine)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: Avengers (comics)\n",
      "==========================\n",
      "   data0:\n",
      "      size: 32\n",
      "      entropy: 0.4489\n",
      "\n",
      "   data1:\n",
      "      size: 244\n",
      "      entropy: 1.4287\n",
      "\n",
      "-->   average entropy: 1.3151\n",
      "\n",
      "\n",
      "Split 1: X-Men\n",
      "==============\n",
      "   data0:\n",
      "      size: 30\n",
      "      entropy: 1.0530\n",
      "\n",
      "   data1:\n",
      "      size: 214\n",
      "      entropy: 1.3792\n",
      "\n",
      "-->   average entropy: 1.3391\n",
      "\n",
      "\n",
      "Split 2: Maggia (comics)\n",
      "========================\n",
      "   data0:\n",
      "      size: 10\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 204\n",
      "      entropy: 1.4040\n",
      "\n",
      "-->   average entropy: 1.3384\n",
      "\n",
      "\n",
      "Split 3: X-Factor (comics)\n",
      "==========================\n",
      "   data0:\n",
      "      size: 4\n",
      "      entropy: 0.8113\n",
      "\n",
      "   data1:\n",
      "      size: 200\n",
      "      entropy: 1.3801\n",
      "\n",
      "-->   average entropy: 1.3689\n",
      "\n",
      "\n",
      "Split 4: Fantastic Four\n",
      "=======================\n",
      "   data0:\n",
      "      size: 4\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 196\n",
      "      entropy: 1.3750\n",
      "\n",
      "-->   average entropy: 1.3475\n",
      "\n",
      "\n",
      "Split 5: The New Avengers (comics)\n",
      "==================================\n",
      "   data0:\n",
      "      size: 4\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 192\n",
      "      entropy: 1.3683\n",
      "\n",
      "-->   average entropy: 1.3404\n",
      "\n",
      "\n",
      "Split 6: X-Mansion\n",
      "==================\n",
      "   data0:\n",
      "      size: 5\n",
      "      entropy: 0.7219\n",
      "\n",
      "   data1:\n",
      "      size: 187\n",
      "      entropy: 1.3515\n",
      "\n",
      "-->   average entropy: 1.3351\n",
      "\n",
      "\n",
      "Split 7: Sinister Six\n",
      "=====================\n",
      "   data0:\n",
      "      size: 7\n",
      "      entropy: 0.9852\n",
      "\n",
      "   data1:\n",
      "      size: 180\n",
      "      entropy: 1.3363\n",
      "\n",
      "-->   average entropy: 1.3232\n",
      "\n",
      "\n",
      "Split 8: Guardians of the Galaxy (2008 team)\n",
      "============================================\n",
      "   data0:\n",
      "      size: 4\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 176\n",
      "      entropy: 1.3263\n",
      "\n",
      "-->   average entropy: 1.2968\n",
      "\n",
      "\n",
      "Split 9: Secret Warriors (Team White)\n",
      "=====================================\n",
      "   data0:\n",
      "      size: 4\n",
      "      entropy: 0.8113\n",
      "\n",
      "   data1:\n",
      "      size: 172\n",
      "      entropy: 1.3071\n",
      "\n",
      "-->   average entropy: 1.2958\n",
      "\n",
      "\n",
      "Split 10: Dark Avengers\n",
      "=======================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 169\n",
      "      entropy: 1.2817\n",
      "\n",
      "-->   average entropy: 1.2754\n",
      "\n",
      "\n",
      "Split 11: Midnight Sons\n",
      "=======================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 166\n",
      "      entropy: 1.2538\n",
      "\n",
      "-->   average entropy: 1.2478\n",
      "\n",
      "\n",
      "Split 12: Thunderbolts (comics)\n",
      "===============================\n",
      "   data0:\n",
      "      size: 8\n",
      "      entropy: 0.9544\n",
      "\n",
      "   data1:\n",
      "      size: 158\n",
      "      entropy: 1.2302\n",
      "\n",
      "-->   average entropy: 1.2169\n",
      "\n",
      "\n",
      "Split 13: Lethal Legion\n",
      "=======================\n",
      "   data0:\n",
      "      size: 7\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 151\n",
      "      entropy: 1.2557\n",
      "\n",
      "-->   average entropy: 1.2001\n",
      "\n",
      "\n",
      "Split 14: Alpha Flight\n",
      "======================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 148\n",
      "      entropy: 1.2332\n",
      "\n",
      "-->   average entropy: 1.2269\n",
      "\n",
      "\n",
      "Split 15: Avengers: The Initiative\n",
      "==================================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 145\n",
      "      entropy: 1.2085\n",
      "\n",
      "-->   average entropy: 1.2026\n",
      "\n",
      "\n",
      "Split 16: Excalibur (comics)\n",
      "============================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 142\n",
      "      entropy: 1.1815\n",
      "\n",
      "-->   average entropy: 1.1760\n",
      "\n",
      "\n",
      "Split 17: X-Corporation\n",
      "=======================\n",
      "   data0:\n",
      "      size: 3\n",
      "      entropy: 0.9183\n",
      "\n",
      "   data1:\n",
      "      size: 139\n",
      "      entropy: 1.1519\n",
      "\n",
      "-->   average entropy: 1.1469\n",
      "\n",
      "\n",
      "Split 18: Squadron Supreme\n",
      "==========================\n",
      "   data0:\n",
      "      size: 10\n",
      "      entropy: 1.2955\n",
      "\n",
      "   data1:\n",
      "      size: 129\n",
      "      entropy: 1.1054\n",
      "\n",
      "-->   average entropy: 1.1191\n",
      "\n",
      "\n",
      "Split 19: Squadron Sinister\n",
      "===========================\n",
      "   data0:\n",
      "      size: 1\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 9\n",
      "      entropy: 0.9183\n",
      "\n",
      "-->   average entropy: 0.8265\n",
      "\n",
      "\n",
      "Split 20: Institute of Evil\n",
      "===========================\n",
      "   data0:\n",
      "      size: 2\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 7\n",
      "      entropy: 0.5917\n",
      "\n",
      "-->   average entropy: 0.4602\n",
      "\n",
      "\n",
      "Split 21: People's Republic of China\n",
      "====================================\n",
      "   data0:\n",
      "      size: 1\n",
      "      entropy: -0.0000\n",
      "\n",
      "   data1:\n",
      "      size: 6\n",
      "      entropy: -0.0000\n",
      "\n",
      "-->   average entropy: -0.0000\n",
      "\n",
      "\n",
      "Max entropy path: 22\n"
     ]
    }
   ],
   "source": [
    "def lowest_split_entropy(data):\n",
    "    lowest = 2 #start with any integer. The highest entropy was about ~1.4\n",
    "    team_name = \"\"\n",
    "    for team in data:\n",
    "        if team != 'faction':\n",
    "            team_entropy = compute_avg_ent_feature(data,team)\n",
    "            if team_entropy < lowest:\n",
    "                lowest = team_entropy\n",
    "                team_name = team\n",
    "    return team_name\n",
    "\n",
    "\n",
    "def max_entropy_path(data):\n",
    "    path = 0\n",
    "    while data.shape[0] > 6: #putting this to 5 = infinite loop on A-Force team\n",
    "        lowest_team = lowest_split_entropy(data)\n",
    "        headline = \"Split %d: %s\" % (path,lowest_team)\n",
    "        print headline + \"\\n\" + \"=\"*len(headline)\n",
    "\n",
    "        s1,ent_1 = compute_entropy(data[data[lowest_team]==1])\n",
    "        s2,ent_2 = compute_entropy(data[data[lowest_team]==0])\n",
    "\n",
    "        print \"   data0:\\n      size: %d\\n      entropy: %.4f\\n\" % (s1, ent_1)\n",
    "        print \"   data1:\\n      size: %d\\n      entropy: %.4f\" % (s2, ent_2)\n",
    "        print \"\\n-->   average entropy: %.4f\\n\\n\" % compute_avg_ent_feature(data,lowest_team)\n",
    "\n",
    "        if ent_1 > ent_2:\n",
    "            data = data[data[lowest_team]==1]\n",
    "        else:\n",
    "            data = data[data[lowest_team]==0]\n",
    "        path += 1\n",
    "    return path\n",
    "path = max_entropy_path(ml_data)\n",
    "print \"Max entropy path: %d\" % path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147 105 160 119 110 179  71 179 101 136 160 160 160  70 105 179 179 165\n",
      " 150 160  67  69 147 179 149 100 179 113 105 160 179 136 160 110 160 105\n",
      " 133 167  64 179 136 150 153 179 116  60  88 179  58 147  97 179  57 113\n",
      " 179 147 160 179 138 138 105 179 120  59  62 160 160 179 116 160 160 179\n",
      "  63 166 179 138  61 149 160  65 105  72  98  66 179 149 138 100 179 150\n",
      " 167  55 179  74 160  68 160 179  86  88  74 179 101  52  95 179 149 179\n",
      " 131 179  96 179 150 167 160 179 179 179  50  50  56 125  50  50 125  50\n",
      "  50  52  50 125  50  50  52 125  50  50  50  50  50 172  50  99  50  50\n",
      "  50  50 154  50  50  50  50  50 106  50  50  50  50 154  50  50 154 125\n",
      "  50  94  50  50  50  50  50  50  50  50 154 107  53 107  50  50  50  50\n",
      "  77  50  50  50  50  50 121 121  50  50  50  50 154 145  50  50  52  57\n",
      "  50 121 154  50  75  50  50 121 154  50  50 121 154 154 145  50  50  50\n",
      " 154 144  50  50  50 142  52 175  50  50 121  50  50  50 121  50  50  50\n",
      "  50  50  50  53  50  83 117 181  80 182 127 137  87 120 108 143 130 133\n",
      " 180 164  84 171 111 142 148  78 174 152 128 142  82  81  79 130 169 134\n",
      " 168 174 114 152 152 126]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "tree_classifier = sklearn.tree.DecisionTreeClassifier(criterion='entropy')\n",
    "tree_classifier.fit(features,target)\n",
    "\n",
    "x = tree_classifier.apply(features)\n",
    "print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (extra): Dimensionality reduction (PCA and ICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this exercise is to learn how to visualize high-dimensional data, and get a feeling of how your Marvel data looks when projected to a plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.2.1**: Apply a PCA transformation to your data. If `X` is your feature matrix, PCA works like:\n",
    "\n",
    ">        pca = sklearn.decomposition.PCA()\n",
    ">        pca.fit(X)\n",
    ">        X_pca = pca.transform(X)\n",
    "\n",
    ">1. What is the dimensionality of `X_pca` compared to `X`? What happened to `X` when you transformed it?\n",
    "2. Plot the first two components/columns of the transformed data and color the points by their class label. My plot looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.1.1.2.png). Comment on the result. What would plotting two other components against each other show you?\n",
    "3. Plot the explained variance ratio of each component. What does this tell you about the dataset? My plot looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.1.1.3.png).\n",
    "\n",
    ">*Hint for 2: `plt.scatter` takes an argument `color` which must receive either a string such as `red` or `blue`, or a list of rgb values or strings such as `['red', 'blue', 'blue', ...]`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "pca = sklearn.decomposition.PCA()\n",
    "\n",
    "pca.fit(features)\n",
    "X_pca = pca.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276L, 276L) (276, 288)\n"
     ]
    }
   ],
   "source": [
    "print X_pca.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.2.2**: In a similar fashion, apply an ICA transformation to your data.\n",
    "\n",
    ">1. Read about [ICA](https://en.wikipedia.org/wiki/Independent_component_analysis).\n",
    "2. Plot the the transformed data on a number of different ICA components. Color the points by their class label. Comment on the differences between the result of ICA and PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
